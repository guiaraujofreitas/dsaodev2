{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaac39e",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9774a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0325e90",
   "metadata": {},
   "source": [
    "# DATA COLLECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3622696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PARAMENTS\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "\n",
    "#link princial do modelo de roupa que p≈ïeciso\n",
    "url= 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "#REQUEST TO URL\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "\n",
    "#BEAUTIFUL OBJECT\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# ================================ PRODUCT DATA =========== # \n",
    "\n",
    "products = soup.find( 'ul', class_='products-listing small' )\n",
    "\n",
    "\n",
    "#list of products\n",
    "products_list= products.find_all ('article',class_=\"hm-product-item\")\n",
    "\n",
    "\n",
    "#product id\n",
    "\n",
    "product_id = [p.get('data-articlecode') for p in products_list]\n",
    "\n",
    "#product category\n",
    "\n",
    "products_category= [p.get('data-category') for p in products_list]\n",
    "\n",
    "#product name \n",
    "\n",
    "#extraction all the name \n",
    "products_list_2=  products.find_all('a', class_='link')\n",
    "\n",
    "products_name =[p.get_text('link') for p in products_list_2]\n",
    "\n",
    "#product price\n",
    "\n",
    "#extraction informations of price\n",
    "products_list_3 = products.find_all('span', class_='price regular')\n",
    "\n",
    "#find all the price in page\n",
    "products_price= [p.get_text('price_regular') for p in products_list_3]\n",
    "\n",
    "data = pd.DataFrame([product_id,products_category,products_name,products_price]).T\n",
    "\n",
    "data.columns = ['product_id','products_category','products_name','products_price']\n",
    "\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bbc854d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 5)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6bfc7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>products_category</th>\n",
       "      <th>products_name</th>\n",
       "      <th>products_price</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2022-05-12-15-23:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1008549006</td>\n",
       "      <td>men_jeans_regular</td>\n",
       "      <td>Regular Jeans</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2022-05-12-15-23:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004199004</td>\n",
       "      <td>men_jeans_skinny</td>\n",
       "      <td>Skinny Cropped Jeans</td>\n",
       "      <td>$ 29.99</td>\n",
       "      <td>2022-05-12-15-23:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0985159001</td>\n",
       "      <td>men_jeans_skinny</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2022-05-12-15-23:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0690449022</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2022-05-12-15-23:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  products_category         products_name products_price  \\\n",
       "0  1024256001     men_jeans_slim            Slim Jeans        $ 19.99   \n",
       "1  1008549006  men_jeans_regular         Regular Jeans        $ 19.99   \n",
       "2  1004199004   men_jeans_skinny  Skinny Cropped Jeans        $ 29.99   \n",
       "3  0985159001   men_jeans_skinny          Skinny Jeans        $ 19.99   \n",
       "4  0690449022   men_jeans_ripped          Skinny Jeans        $ 39.99   \n",
       "\n",
       "       scrapy_datetime  \n",
       "0  2022-05-12-15-23:02  \n",
       "1  2022-05-12-15-23:02  \n",
       "2  2022-05-12-15-23:02  \n",
       "3  2022-05-12-15-23:02  \n",
       "4  2022-05-12-15-23:02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf4846",
   "metadata": {},
   "source": [
    "# DATA  COLLECT BY PRODUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d14ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key browser\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36 OPR/37.0.2178.54'}\n",
    "\n",
    "#empty Data Frame (to insert the joins)\n",
    "df_compositions= pd.DataFrame()\n",
    "\n",
    "aux= []\n",
    "\n",
    "cols= ['Composition','Size','Art. No.','Fit','messages.garmentLength','messages.waistRise',\n",
    "'Care instructions',\n",
    " 'Material',\n",
    " 'Description',\n",
    " 'Imported',\n",
    " 'Concept',\n",
    " 'Nice to know']\n",
    "    \n",
    "df_pattern = pd.DataFrame( columns=  cols )\n",
    "\n",
    "#df_pattern = pd.DataFrame( columns=['Size','Art. No.','Composition'] )\n",
    "\n",
    "\n",
    "#API Requests\n",
    "for i in range(len(data)):\n",
    "    \n",
    "    url= 'https://www2.hm.com/en_us/productpage.'+ data.loc[i,'product_id'] +'.html'\n",
    "    #url= 'https://www2.hm.com/en_us/productpage.'+ '1024256001' +'.html'\n",
    "    \n",
    "    #print('Product:{}'.format(url))\n",
    "    \n",
    "    \n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    #Beautifull Souo object\n",
    "    soup= BeautifulSoup(page.text,'html.parser')\n",
    "\n",
    "    ### ===================== color name ======================\n",
    "\n",
    "    products_list= soup.find_all('a',class_='filter-option miniature active') + soup.find_all('a',class_='filter-option miniature') \n",
    "\n",
    "    #product id\n",
    "    products_id = [p.get('data-articlecode') for p in products_list]\n",
    "\n",
    "    #color name\n",
    "    color_name = [p.get('data-color') for p in products_list]\n",
    "\n",
    "    #create data frame\n",
    "\n",
    "    df_color = pd.DataFrame([products_id,color_name]).T\n",
    "\n",
    "    #rename the columns of DF\n",
    "    df_color.columns= ['Art. No.','color_name']\n",
    "    \n",
    "    \n",
    "    for j in range(len(df_color)):\n",
    "        url2= 'https://www2.hm.com/en_us/productpage.'+ df_color.loc[j,'Art. No.'] +'.html'\n",
    "        #print( 'Color: {}'.format( url2 ) )\n",
    "        \n",
    "    \n",
    "        page = requests.get( url2, headers=headers )\n",
    "\n",
    "        #Beautifull Souo object\n",
    "        soup= BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "        #=========================product name ==============================\n",
    "        product_name = soup.find_all('h1',class_='primary product-item-headline')\n",
    "        product_name = product_name[0].get_text()\n",
    "        \n",
    "        # ==================== product price ======================= #\n",
    "        \n",
    "        product_price= soup.find_all('div',class_='primary-row product-item-price')\n",
    "        product_price = re.findall(r'\\d+?.\\d+',product_price[0].get_text())[0]\n",
    "       \n",
    "        \n",
    "        \n",
    "        #create new colum styly_id\n",
    "        #df_color['stlye_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "\n",
    "        #create new colum color_id\n",
    "        #df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "        # ============================== composition =============================== #\n",
    "\n",
    "        #composition\n",
    "        composition_list= soup.find_all('div', class_ = 'details-attributes-list-item')\n",
    "        \n",
    "        #composition_list = soup.find_all('dd','details-list-item')\n",
    "        #product_composition = composition_list[3]\n",
    "\n",
    "        product_composition = [list(filter (None, p.get_text().split('\\n') ) ) for p in composition_list]\n",
    "        \n",
    "\n",
    "        if product_composition != []:\n",
    "\n",
    "            #created the dataframe aux\n",
    "            df_composition= pd.DataFrame(product_composition).T\n",
    "        \n",
    "            \n",
    "            #renome the columns\n",
    "            df_composition.columns= df_composition.iloc[0]\n",
    "\n",
    "            #delete the first row and delete the columns that is the empty\n",
    "            df_composition= df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "            \n",
    "            \n",
    "            #select columns \n",
    "            #df_composition= df_composition[['Composition','Art. No.']]\n",
    "\n",
    "            #delete the first row and delete the columns that is the empty\n",
    "            #df_composition= df_aux.iloc[1:3]\n",
    "\n",
    "            #copying the code and the model to row the below\n",
    "            #df_composition = df_composition.fillna(method='ffill')\n",
    "\n",
    "\n",
    "            #rename the data frame to a new variable\n",
    "            #df_composition = df_composition.copy(True)\n",
    "\n",
    "            #remove pocket lining, shell and lining\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining:','',regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Shell:','',regex=True)\n",
    "            df_composition['Composition'] = df_composition['Composition'].replace('Lining:','',regex=True)\n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "            # garantee the same number of columns\n",
    "            df_composition = pd.concat( [df_pattern, df_composition], axis=0 )\n",
    "\n",
    "            #rename the columns \n",
    "            #df_composition.columns = ['composition', 'size', 'art. no.', 'fit', 'messages.garmentLength',\n",
    "            #'messages.waistRise', 'care instructions', 'material', 'description',\n",
    "            #'imported', 'concept', 'nice to know','more sustainable materials']\n",
    "\n",
    "            #create new colum styly_id\n",
    "            #df_composition['stlye_id'] =df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "\n",
    "            #create new colum color_id\n",
    "            #df_composition['color_id'] = df_composition['Art. No.'].apply(lambda x: x[-3:])\n",
    "\n",
    "            #keep new columns if it shows\n",
    "            aux= aux + df_composition.columns.tolist()\n",
    "\n",
    "    \n",
    "            #merge dataframe of color and composition \n",
    "            df_composition= pd.merge(df_composition,df_color, how='left', on ='Art. No.')\n",
    "            \n",
    "\n",
    "\n",
    "            #all products \n",
    "            df_compositions = pd.concat([df_composition,df_compositions], axis=0)\n",
    "\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        None\n",
    "\n",
    "#select just columns necessary\n",
    "df_compositions= df_compositions[['Art. No.','Composition','color_name','Size','Fit']]\n",
    "\n",
    "#rename columns\n",
    "df_compositions.rename(columns = {'Art. No.':'product_id','Composition':'composition','Size':'size','Fit':'fit'},inplace=True)\n",
    "\n",
    "# Join Showroom data + details\n",
    "\n",
    "df_compositions['stlye_id'] = df_compositions['product_id'].apply( lambda x: x[:-3] )\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply( lambda x: x[-3:] )\n",
    "\n",
    "df_compositions['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d-%H-%M:%S')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f44a8268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43e4ca60",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "data = pd.read_csv('/home/guilherme/Documentos/repos/ds_ao_dev/projeto_webscraping/df_raw.csv')\n",
    "\n",
    "#delete the columns not necessery\n",
    "data = data.drop(['Unnamed: 0' ],axis=1)\n",
    "\n",
    "#product id\n",
    "\n",
    "data = data.dropna(subset=['product_id'])\n",
    "\n",
    "#product category\n",
    "\n",
    "#product name\n",
    "data['products_name']= data['products_name'].apply(lambda x: x.replace(' ','_').lower())\n",
    "#products_price\n",
    "\n",
    "#j√° fiz o tratamento anteriomente\n",
    "\n",
    "#product datetime\n",
    "\n",
    "\n",
    "data['scrapy_datetime']= pd.to_datetime(data['scrapy_datetime'])\n",
    "\n",
    "#style id\n",
    "\n",
    "#color id\n",
    "\n",
    "#color name\n",
    "data['color_name']= data['color_name'].apply(lambda x: x.replace(' ','_').replace('/','_').lower() if pd.notnull(x) else x)\n",
    "\n",
    "#Composition\n",
    "\n",
    "data['Composition']= data['Composition'].where(~data['Composition'].str.contains('Pocket lining:',na=False) ) \n",
    "\n",
    "data['Composition']= data['Composition'].where(lambda x: ~x.str.contains('Shell:',na=False) )\n",
    "\n",
    "data['Composition'] = data['Composition'].where(lambda x: ~x.str.contains('Lining:',na=False) )\n",
    "\n",
    "#drop duplicates\n",
    "#first were making drop the that are duplicates (excect the colum Composition), because the colums is duplicate\n",
    "data= data.drop_duplicates(subset= ['product_id', 'products_category', 'products_name', 'products_price',\n",
    "       'scrapy_datetime', 'stlye_id', 'color_id', 'color_name'],keep='last')\n",
    "\n",
    "   \n",
    "#reset index\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#break composition by comma (separando as composi√ß√µes dos materiais por coluna)\n",
    "df1 = data['Composition'].str.split(',',expand=True)\n",
    "\n",
    "#Cotton| Spandex | Polyester |  Elastomultiester\n",
    "#2 etapa\n",
    "#definir as colunas (organizando as colunas por m√°teria-prima)\n",
    "\n",
    "#criando Dataframe vazio com o mesmo tamanho do dataframe original para prencher com as respectivas composi√ß√µes\n",
    "df_ref = pd.DataFrame(index=np.arange(len(data) ),columns=['cotton','spandex','polyester','elastomultiester'])\n",
    "\n",
    "#cotton\n",
    "#pegando a coluna da composi√ß√£o cotton\n",
    "df_cotton = df1[0]\n",
    "\n",
    "#colocando o nome na coluna \n",
    "df_cotton.name = 'cotton'\n",
    "#mesclando com a tabela vazia \n",
    "df_ref = pd.concat([df_ref,df_cotton],axis=1)\n",
    "\n",
    "#dropando as colunas duplicadas\n",
    "df_ref= df_ref.iloc[:,~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "df_ref['cotton'] = df_ref['cotton'].fillna( 'Cotton 0%' )\n",
    "\n",
    "#polyester \n",
    "\n",
    "#adicionando as coluna da composi√ß√£o Polyester\n",
    "df_polyester =df1[1].where(lambda x: x.str.contains('Polyester',na=True))\n",
    "\n",
    "#renomeando a coluna\n",
    "df_polyester.name= 'polyester'\n",
    "\n",
    "\n",
    "df_ref= pd.concat([df_ref,df_polyester],axis=1)\n",
    "\n",
    "#dropando as colunas duplicadas\n",
    "df_ref= df_ref.iloc[:,~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "df_ref['polyester'] = df_ref['polyester'].fillna( 'Polyester 0%' )\n",
    "\n",
    "#Elastomultiester\n",
    "\n",
    "#coletando apenas a composi√ß√£o elastano\n",
    "df_elastomultiester =df1[1].where(lambda x: x.str.contains('Elastomultiester',na=True))\n",
    "\n",
    "#renomenado a coluna eslastano\n",
    "df_elastomultiester.name= 'elastomultiester'\n",
    "\n",
    "\n",
    "#mesclando com df_ref vazio e com a mesma quantidade de linhas que h√° no index\n",
    "df_ref= pd.concat([df_ref,df_elastomultiester],axis=1)\n",
    "\n",
    "#dropando as colunas duplicadas\n",
    "df_ref= df_ref.iloc[:,~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "df_ref['elastomultiester'] = df_ref['elastomultiester'].fillna( 'Elastomultiester 0%' )\n",
    "\n",
    "#Spandex\n",
    "\n",
    "#coletando composi√ß√£o spandex da segunda coluna df1\n",
    "\n",
    "df_spandex= df1[1].where(lambda x: x.str.contains('Spandex',na=True))\n",
    "\n",
    "df_spandex.name = 'spandex'\n",
    "\n",
    "#combine from spandex botth columns 1 and 2\n",
    "\n",
    "df_spandex = df_spandex.combine_first(df1[2])\n",
    "\n",
    "\n",
    "df_ref= pd.concat([df_ref,df_spandex],axis=1)\n",
    "\n",
    "df_ref= df_ref.iloc[:,~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "df_ref['spandex'] = df_ref['spandex'].fillna('Spandex 0%')\n",
    "\n",
    "#coletando composi√ß√£o spandex da terceira coluna do df1\n",
    "\n",
    "#df_spandex_2= df1[2].where(lambda x: x.str.contains('Spandex',na=True))\n",
    "             \n",
    "#df_spandex_2.name= 'spandex'\n",
    "\n",
    "#df_ref= pd.concat([df_ref,df_spandex_2],axis=1)\n",
    "\n",
    "#df_ref= df_ref.iloc[:,~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "\n",
    "\n",
    "#final join\n",
    "\n",
    "data= pd.concat([data,df_ref],axis=1)\n",
    "\n",
    "#coletando apenas os numeros e transformando em n√∫meros inteiros\n",
    "\n",
    "#format composition data\n",
    "\n",
    "#cotton\n",
    "data['cotton']= data['cotton'].apply(lambda x: int(re.search('\\d+',x ).group(0))/100 if pd.notnull(x) else x)\n",
    "\n",
    "#spandex\n",
    "data['spandex'] =data['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0)) /100 if pd.notnull(x) else x)\n",
    "\n",
    "#polyester\n",
    "data['polyester']= data['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "\n",
    "#elastomultiester\n",
    "data['elastomultiester']=data['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0)) /100 if pd.notnull(x) else x)\n",
    "\n",
    "#drop columns\n",
    "data= data.drop(['Composition'],axis=1)\n",
    "\n",
    "#drop duplicates\n",
    "\n",
    "\n",
    "data= data.drop_duplicates()\n",
    "\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
